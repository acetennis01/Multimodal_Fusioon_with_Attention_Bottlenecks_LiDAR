/var/spool/slurm/d/job196866/slurm_script: line 9: SBATCH: command not found
/opt/miniconda3/envs/opence-v1.5.1/lib/python3.9/site-packages/torch/nn/functional.py:3631: UserWarning: Default upsampling behavior when mode=linear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.
  warnings.warn(
Traceback (most recent call last):
  File "/home/abhia2/Projects/Multimodal_Fusioon_with_Attention_Bottlenecks_LiDAR/train_test.py", line 171, in <module>
    train_test(args=opts)
  File "/home/abhia2/Projects/Multimodal_Fusioon_with_Attention_Bottlenecks_LiDAR/train_test.py", line 158, in train_test
    loss, acc = train_one_epoch(trainloader, model, optimizer, loss_fn, args.device)
  File "/home/abhia2/Projects/Multimodal_Fusioon_with_Attention_Bottlenecks_LiDAR/train_test.py", line 56, in train_one_epoch
    preds = model(point_clouds, rgb_frames)
  File "/opt/miniconda3/envs/opence-v1.5.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/abhia2/Projects/Multimodal_Fusioon_with_Attention_Bottlenecks_LiDAR/models/visual_model.py", line 128, in forward
    pc, rgb = self.forward_encoder(pc, rgb)  # Encode features
  File "/home/abhia2/Projects/Multimodal_Fusioon_with_Attention_Bottlenecks_LiDAR/models/visual_model.py", line 118, in forward_encoder
    pc, rgb = blk(pc, rgb)
  File "/opt/miniconda3/envs/opence-v1.5.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/home/abhia2/Projects/Multimodal_Fusioon_with_Attention_Bottlenecks_LiDAR/models/pet_modules.py", line 108, in forward
    pc = pc + self.pc_attn(self.pc_norm1(pc), self.pc_norm1(pc), self.pc_norm1(pc))[0]
  File "/opt/miniconda3/envs/opence-v1.5.1/lib/python3.9/site-packages/torch/nn/modules/module.py", line 1102, in _call_impl
    return forward_call(*input, **kwargs)
  File "/opt/miniconda3/envs/opence-v1.5.1/lib/python3.9/site-packages/torch/nn/modules/activation.py", line 1003, in forward
    attn_output, attn_output_weights = F.multi_head_attention_forward(
  File "/opt/miniconda3/envs/opence-v1.5.1/lib/python3.9/site-packages/torch/nn/functional.py", line 5103, in multi_head_attention_forward
    attn_output = linear(attn_output, out_proj_weight, out_proj_bias)
  File "/opt/miniconda3/envs/opence-v1.5.1/lib/python3.9/site-packages/torch/nn/functional.py", line 1848, in linear
    return torch._C._nn.linear(input, weight, bias)
RuntimeError: CUDA out of memory. Tried to allocate 174.00 MiB (GPU 0; 15.00 GiB total capacity; 13.21 GiB already allocated; 51.38 MiB free; 13.70 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
